.. _bookmarks:

=========
Bookmarks
=========

* `MTEB: Massive Text Embedding Benchmark <https://arxiv.org/abs/2210.07316>`_
* `Gecko: Versatile Text Embeddings Distilled from Large Language Models <https://arxiv.org/abs/2403.20327>`_
* `SONAR <https://github.com/facebookresearch/SONAR>`_
* `Don't use cosine similarity carelessly <https://p.migdal.pl/blog/2025/01/dont-use-cosine-similarity>`_
* `Lossless Compression of Vector IDs for Approximate Nearest Neighbor Search <https://arxiv.org/abs/2501.10479>`_
* `The Best Way to Use Text Embeddings Portably is With Parquet and Polars <https://minimaxir.com/2025/02/embeddings-parquet/>`_
* `NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models <https://arxiv.org/abs/2405.17428>`_
* `Mapping LLM embeddings in three dimensions <https://tomhazledine.com/mapping-llm-embeddings-in-3d/>`_
* `Harnessing the universal geometry of embeddings <https://news.ycombinator.com/item?id=44054425>`_
* `Vertex AI quickstart <https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#gen-ai-sdk-for-python>`_
* `A visual exploration of vector embeddings <https://news.ycombinator.com/item?id=44120306>`_
* `Train the best sentence embedding model ever with 1B training pairs <https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354>`_
* `sentence-transformers/all-MiniLM-L6-v2 <https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2>`_
